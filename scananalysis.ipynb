{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e9bf7-8d04-4855-9901-22066f77d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 ## working with large image files, need to increase max pixels to avoid DDOS error\n",
    "tiff_paths = []\n",
    "raw_tiff = [] ## imread image files\n",
    "raw_arr = [] ## images as numpy arrays\n",
    "names = []\n",
    "colors = list(mcolors.BASE_COLORS) + list(mcolors.TABLEAU_COLORS)\n",
    "del colors[7] ## get rid of white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dc3c4-b186-4d4d-a1c4-57f25e16e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING DIRECTORIES - **DO NOT RUN AGAIN, WILL RESET ALL IMAGES**\n",
    "def create_dir():\n",
    "    os.mkdir('images')\n",
    "    directories = ['CZI','TIFF','MULTIPLIED','BACKGROUND_THRESHOLDED','SPLIT CHANNELS','CROPPED','HEATMAP']\n",
    "    for i in directories:\n",
    "        os.mkdir('images/' + i)\n",
    "        \n",
    "create_dir()\n",
    "        \n",
    "def create_dir_2():\n",
    "    for i in range(len(names)):\n",
    "        os.mkdir('images/CROPPED' + names[i])\n",
    "        os.mkdir('images/CROPPED' + names[i] + '/c1')\n",
    "        os.mkdir('images/CROPPED' + names[i] + '/c2')\n",
    "\n",
    "create_dir_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39c028-44e8-4e78-9503-91e4c6dd429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Images in - **ONLY NEED TO RUN ONCE**\n",
    "\n",
    "## CONVERT CZI FILES IN PROGRESS\n",
    "\n",
    "def read_czi(read_path,write_path):\n",
    "    javabridge.start_vm(class_path=bioformats.JARS)\n",
    "    \n",
    "    image, scale = bioformats.load_image(read_path, rescale=False, wants_max_intensity=False)\n",
    "    bioformats.write_image(write_path, image)\n",
    "    \n",
    "    javabridge.kill_vm()\n",
    "\n",
    "def convert_czi(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and '.czi' in f:\n",
    "            read_czi('images/CZI','images/TIFF')\n",
    "\n",
    "def read_tiff(path):\n",
    "    \"\"\"\n",
    "    path - Path to the multipage-tiff file\n",
    "    \"\"\"\n",
    "    img = Image.open(path)\n",
    "    arrays = []\n",
    "    images = []\n",
    "    \n",
    "    images.append(img)\n",
    "    arrays.append(np.array(img))\n",
    "    for i in range(img.n_frames):\n",
    "        img.seek(i)\n",
    "        arrays.append(np.array(img))\n",
    "        images.append(img)\n",
    "    raw_tiff.append(images)\n",
    "    return np.array(arrays)\n",
    "\n",
    "def convert_tiff(directory,lst):\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f != (directory+'/'+\".DS_Store\"):\n",
    "            tiff_paths.append(f)\n",
    "    print(len(tiff_paths))\n",
    "    for path in tiff_paths:\n",
    "        lst.append(read_tiff(path))\n",
    "        \n",
    "convert_tiff('images/TIFF',raw_arr)\n",
    "print(\"Converted Tiffs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eda958-0dd8-48cd-ac51-d2fab738833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INTENSITY BASED ANALYSIS\n",
    "\n",
    "img_thresholded = []\n",
    "img_multiplied = []\n",
    "signal_binary = []\n",
    "img_integrals = []\n",
    "img_ratios = []\n",
    "\n",
    "def threshold_img(img, threshold, name):\n",
    "    thresholded = np.where(img > threshold, 1, 0)\n",
    "    thresholded = thresholded.astype(np.uint16)\n",
    "    \n",
    "    save_img('images/BACKGROUND_THRESHOLDED',thresholded,'thres',name)               # SAVE IMAGE\n",
    "    return thresholded\n",
    "\n",
    "def otsu_threshold_img(img, name):\n",
    "    otsu_thres = cv2.threshold(img, 0, 1, c]v2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    save_img('images/OTSU_THRESHOLDED',otsu_thres,'otsu_thres',name)               # SAVE IMAGE\n",
    "    return otsu_thres\n",
    "\n",
    "def multiply_img(img, background, name):\n",
    "    multiplied = np.multiply(np.array(img),np.array(background))\n",
    "    multiplied = multiplied.astype(np.uint16)\n",
    "\n",
    "    save_img('images/MULTIPLIED',multiplied,'mult',name)                  # SAVE IMAGE\n",
    "    return multiplied\n",
    "\n",
    "def binary_img(img, name):\n",
    "    binary = np.where(img > 0, 1, 0)\n",
    "    save_img('images/BINARY',binary,'binary',name)\n",
    "    return binary\n",
    "\n",
    "def summation(background, signals):\n",
    "    return (np.sum(background), np.sum(signals))\n",
    "\n",
    "def save_img(path,arr,prefix,name):\n",
    "    img = Image.fromarray(arr.astype(np.uint16))\n",
    "    img.save(path + '/' + prefix + ' ' + name + '.tif')\n",
    "\n",
    "names = [path[12:path.find('.tif')] for path in tiff_paths]\n",
    "\n",
    "\n",
    "## PROCESSING ALL OF THE IMAGES\n",
    "\n",
    "for i in trange(len(raw_arr)):\n",
    "    img_thresholded.append(otsu_threshold_img(raw_arr[i][1], names[i]))\n",
    "    img_multiplied.append(multiply_img(raw_arr[i][2], img_thresholded[i], names[i]))\n",
    "    img_integrals.append(summation(img_thresholded[i], img_multiplied[i]))\n",
    "    img_ratios.append(img_integrals[i][1]/img_integrals[i][0])\n",
    "    \n",
    "print('processed')\n",
    "    \n",
    "## DATA PRESENTATION\n",
    "for i in range(len(names)):\n",
    "    print(names[i], '-', img_ratios[i])\n",
    "    print(img_integrals[i])\n",
    "plt.bar(names, img_ratios,color=colors[:len(names)])\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b1d05b-0ea9-4c4c-8730-518bed0c6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HEAT MAP OF IMAGES - GAUSSIAN BLUR, save in images/HEATMAP\n",
    "def gauss_blur():\n",
    "    for i in range(len(names)):\n",
    "        img = raw_tiff[i].convert('I;16').filter(ImageFilter.GaussianBlur(radius = 60))\n",
    "        img.save('images/HEATMAP/heatmap', names[i])\n",
    "    print('done')\n",
    "    \n",
    "gauss_blur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d0e92-663e-4321-acf3-0366677218f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL PROFILER CELL-BASED ANALYSIS\n",
    "\n",
    "import cellprofiler_core.pipeline\n",
    "import cellprofiler_core.preferences\n",
    "import cellprofiler_core.utilities.java\n",
    "import cellprofiler.modules.identifyprimaryobjects\n",
    "\n",
    "cp_data = np.empty(shape=(len(names),2))\n",
    "\n",
    "# BATCH IMAGES\n",
    "def crop_image(directory,img,w,h):\n",
    "    cropped_lst = []\n",
    "    crop_w = math.floor(img.size[0]/w)\n",
    "    crop_h = math.floor(img.size[1]/h)\n",
    "    for i in range(0,h):\n",
    "        for j in range(0,w):\n",
    "            (img.crop((j*crop_w, i*crop_h, j*crop_w+crop_w, i*crop_h+crop_h))).save(directory+'_cropped'+str(i*w+j)+'.tif')\n",
    "            \n",
    "## CROP SIGNALS\n",
    "def crop_signals():\n",
    "    for filename in os.listdir('images/MULTIPLIED'):\n",
    "        f = os.path.join('images/MULTIPLIED', filename)\n",
    "        if os.path.isfile(f) and 'HBC' in f:\n",
    "            crop_image(('images/CROPPED/' + filename[5:filename.find('.tif')] + '/c2/'),(Image.open(f)),30,30)\n",
    "            print(filename)\n",
    "    \n",
    "## THRESHOLDED DAPI\n",
    "def threshold_dapi(thres,back,name):\n",
    "    multiplied = np.multiply(np.array(thres),np.array(back))\n",
    "    multiplied = multiplied.astype(np.uint16)\n",
    "\n",
    "    save_img('images/BACKGROUND_MULT',multiplied,'backmult',name)                  # SAVE IMAGE\n",
    "\n",
    "def crop_dapi():\n",
    "    for filename in os.listdir('images/BACKGROUND_MULT'):\n",
    "        f = os.path.join('images/BACKGROUND_MULT', filename)\n",
    "        if os.path.isfile(f) and 'HBC' in f:\n",
    "            crop_image(('images/CROPPED/' + filename[9:filename.find('.tif')] + '/c1/'),(Image.open(f)),30,30)\n",
    "            print(filename)\n",
    "\n",
    "def cp_analyse(path):\n",
    "    cellprofiler_core.preferences.set_headless()\n",
    "\n",
    "    cellprofiler_core.utilities.java.start_java()\n",
    "\n",
    "    pipeline = cellprofiler_core.pipeline.Pipeline()\n",
    "    pipeline.load('cellprofiler_analysis.cppipe')\n",
    "\n",
    "    file_list = list(pathlib.Path('.').absolute().glob(path+'/*.tif'))\n",
    "    files = [file.as_uri() for file in file_list]\n",
    "    pipeline.read_file_list(files)\n",
    "\n",
    "    output_measurements = pipeline.run()\n",
    "    \n",
    "    return_value = len(output_measurements.get_measurement_columns())\n",
    "\n",
    "    cellprofiler_core.utilities.java.stop_java()\n",
    "    return return_value\n",
    "\n",
    "def analyse_all():\n",
    "    for i in range(len(names)):\n",
    "        cp_data[i][0].append(cp_analyse('images/CROPPED/' + names[i] + '/c1'))\n",
    "        c2_data[i][1].append(cp_analyse('images/CROPPED/' + names[i] + '/c2'))\n",
    "\n",
    "## DATA PRESENTATION\n",
    "def do_the_data():\n",
    "    for i in range(len(names)):\n",
    "        print(names[i], '-', cell_ratios[i], '-', cp_data[i][0], '-', cp_data[i][1])\n",
    "    plt.bar(names, cell_ratios,color=colors[:len(names)])\n",
    "    plt.xticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "crop_signals()\n",
    "for i in range(len(names)):\n",
    "    threshold_dapi(img_thresholded[i],raw_arr[i][0],names[i])\n",
    "crop_dapi()\n",
    "crop_22()\n",
    "print('done')\n",
    "    \n",
    "process_results()\n",
    "cell_ratios = [datum[0]/datum[1] for datum in cp_data]\n",
    "do_the_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f753b8c-75bd-4e34-a970-b2c3814f96e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 71.68553997214495)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a36e75e4bb448579d4dbf572beaa3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/zszwkwsd6p121df2kwsxf7hr0000gn/T/ipykernel_19089/2790701514.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  intensity_r_ml = intensity_m + (((intensity_n-intensity_m)/r_mn) * r_ml)\n"
     ]
    }
   ],
   "source": [
    "## Heterogeneity score\n",
    "from skimage.draw import line\n",
    "from itertools import combinations\n",
    "\n",
    "test_img = np.random.rand(50,50)\n",
    "test_img = test_img * 256\n",
    "test_img = np.floor(test_img)\n",
    "\n",
    "def heterogeneity_score(img):\n",
    "    #average absolute intensity\n",
    "    aai_lst = [[],[]]\n",
    "    aai_dict = {}\n",
    "    all_points_1 = combinations\n",
    "    xy_coords1 = np.flip(np.column_stack(np.where(img)), axis=1)\n",
    "    xy_coords2 = np.flip(np.column_stack(np.where(img)), axis=1)\n",
    "    \n",
    "    for i in trange(len(xy_coords1)):\n",
    "        for j in range(len(xy_coords2)):\n",
    "            x_1 = xy_coords1[i][0]\n",
    "            y_1 = xy_coords1[i][1]\n",
    "            x_2 = xy_coords2[j][0]\n",
    "            y_2 = xy_coords2[j][1]\n",
    "            calculated_i = avg_intensity(img,x_1,y_1,x_2,y_2)\n",
    "            # print(calculated_i)\n",
    "            if calculated_i[0] in aai_lst[0]:\n",
    "                aai_lst[1][aai_lst[0].index(calculated_i[0])].append(calculated_i[1])\n",
    "            else:\n",
    "                aai_lst[0].append(calculated_i[0])\n",
    "                aai_lst[1].append([calculated_i[1]])\n",
    "    \n",
    "    return(aai_lst)\n",
    "    \n",
    "def avg_intensity(img,x_m,y_m,x_n,y_n):\n",
    "    intensity_m = img[y_m][x_m]\n",
    "    intensity_n = img[y_n][x_n]\n",
    "    r_mn = math.dist((x_m,y_m), (x_n,y_n))\n",
    "    bresenham_points = line(x_m,y_m,x_n,y_n)\n",
    "    summation = 0\n",
    "    \n",
    "    for i in range(len(bresenham_points[0])):\n",
    "        x_l = bresenham_points[0][i]\n",
    "        y_l = bresenham_points[1][i]\n",
    "        intensity_l = img[y_l][x_l]\n",
    "        r_ml = math.dist((x_m,y_m), (x_l,y_l))\n",
    "        \n",
    "        # print(x_l,y_l)\n",
    "        intensity_r_ml = intensity_m + (((intensity_n-intensity_m)/r_mn) * r_ml)\n",
    "        summation += abs(intensity_r_ml - intensity_l)\n",
    "    \n",
    "    avg_abs_intensity = summation / len(bresenham_points[0])\n",
    "    return (len(bresenham_points[0]), avg_abs_intensity)\n",
    "\n",
    "print(avg_intensity(test_img,10,12,25,40))\n",
    "test = heterogeneity_score(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f7077-6ebf-4057-a2f0-6f82eb9873cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[1][35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b1c453d-6bb7-42b8-9c49-fe226f2a9d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 6 4 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/zszwkwsd6p121df2kwsxf7hr0000gn/T/ipykernel_19089/3202323700.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  listt = np.array([[1],[1,6,4]])\n"
     ]
    }
   ],
   "source": [
    "listt = np.array([[1],[1,6,4]])\n",
    "listt = np.append(listt[1],[5])\n",
    "print(listt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce56ec-8cd4-4f5f-a5fe-5cf06b0d0a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
